# ç¬¬7ç«  Text2SQL Agent ç¬¬ä¸€éƒ¨åˆ†:BM25 + å‘é‡æ··åˆæ£€ç´¢ä¸æ™ºèƒ½è¡¨ç»“æ„åŒ¹é…

## ç« èŠ‚ç›®æ ‡

1. ç†è§£ Text2SQL çš„æ ¸å¿ƒæŒ‘æˆ˜,æŒæ¡ä»è‡ªç„¶è¯­è¨€åˆ° SQL çš„è½¬æ¢æ€è·¯
2. å­¦ä¼š BM25 ç®—æ³•çš„åŸç†ä¸ Jieba åˆ†è¯ä¼˜åŒ–,å®ç°ç²¾å‡†å…³é”®è¯åŒ¹é…
3. æŒæ¡ FAISS å‘é‡ç´¢å¼•æ„å»º,ä½¿ç”¨ DashScope Embedding API ç”Ÿæˆè¯­ä¹‰å‘é‡
4. å®è·µ RRF(Reciprocal Rank Fusion)èåˆç­–ç•¥,ç»“åˆ BM25 ä¸å‘é‡æ£€ç´¢ä¼˜åŠ¿
5. ä½¿ç”¨ DashScope Rerank API è¿›è¡Œç»“æœé‡æ’åº,æå‡å¬å›å‡†ç¡®ç‡

## ä¸€ã€Text2SQL çš„æ ¸å¿ƒæŒ‘æˆ˜

### 1.1 ä¸ºä»€ä¹ˆ Text2SQL å¾ˆéš¾

**æŒ‘æˆ˜1:è‡ªç„¶è¯­è¨€çš„æ­§ä¹‰æ€§**

```
ç”¨æˆ·:"æŸ¥è¯¢æœ€è¿‘ä¸€å‘¨çš„è®¢å•"

å¯èƒ½çš„ç†è§£:
1. æœ€è¿‘7å¤©çš„è®¢å•(2024-01-01 åˆ° 2024-01-07)
2. æœ€è¿‘ä¸€ä¸ªè‡ªç„¶å‘¨çš„è®¢å•(2024-01-01 å‘¨ä¸€ åˆ° 2024-01-07 å‘¨æ—¥)
3. è·ç¦»ç°åœ¨æœ€è¿‘çš„7æ¡è®¢å•è®°å½•

å¯¹åº”çš„SQL:
1. WHERE order_date >= DATE_SUB(CURDATE(), INTERVAL 7 DAY)
2. WHERE WEEK(order_date) = WEEK(CURDATE())
3. ORDER BY order_date DESC LIMIT 7
```

**æŒ‘æˆ˜2:è¡¨ç»“æ„å¤æ‚æ€§**

```
æ•°æ®åº“æœ‰ 50 å¼ è¡¨,æ¯å¼ è¡¨ 20 ä¸ªå­—æ®µ
ç”¨æˆ·:"æŸ¥è¯¢é”€å”®æ•°æ®"

é—®é¢˜:
- å“ªå¼ è¡¨æ˜¯é”€å”®è¡¨?(t_sales_orders? t_order_details? t_products?)
- éœ€è¦å…³è”å“ªäº›è¡¨?(å®¢æˆ·è¡¨? äº§å“è¡¨?)
- å­—æ®µåæ˜¯ä»€ä¹ˆ?(total_amount? sale_amount? order_amount?)
```

**æŒ‘æˆ˜3:SQL è¯­æ³•å¤šæ ·æ€§**

```
åŒä¸€ä¸ªéœ€æ±‚,å¤šç§SQLå†™æ³•:

éœ€æ±‚:"ç»Ÿè®¡æ¯ä¸ªçœä»½çš„è®¢å•æ•°"

å†™æ³•1(GROUP BY):
SELECT province, COUNT(*) FROM orders GROUP BY province

å†™æ³•2(å­æŸ¥è¯¢):
SELECT province, (SELECT COUNT(*) FROM orders o2 WHERE o2.province = o1.province)
FROM orders o1 GROUP BY province

å†™æ³•3(çª—å£å‡½æ•°):
SELECT DISTINCT province, COUNT(*) OVER (PARTITION BY province) FROM orders
```

### 1.2 è§£å†³æ–¹æ¡ˆæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç”¨æˆ·æŸ¥è¯¢   â”‚  "ç»Ÿè®¡å„çœè®¢å•æ•°"
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç¬¬1æ­¥:è¡¨ç»“æ„æ£€ç´¢       â”‚  æ··åˆæ£€ç´¢(BM25+å‘é‡+é‡æ’)
â”‚ ç›®æ ‡:æ‰¾åˆ°ç›¸å…³çš„è¡¨      â”‚  â†’ ç­›é€‰å‡º t_sales_orders, t_customers
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç¬¬2æ­¥:ç”Ÿæˆ SQL         â”‚  Prompt Engineering
â”‚ ç›®æ ‡:æ ¹æ®è¡¨ç»“æ„ç”ŸæˆSQL â”‚  â†’ SELECT province, COUNT(*) FROM ...
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç¬¬3æ­¥:æ‰§è¡Œ SQL         â”‚  æ•°æ®åº“æŸ¥è¯¢
â”‚ ç›®æ ‡:è·å–æŸ¥è¯¢ç»“æœ      â”‚  â†’ [{province: "åŒ—äº¬", count: 100}, ...]
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç¬¬4æ­¥:LLM æ€»ç»“         â”‚  æ•°æ®åˆ†æ
â”‚ ç›®æ ‡:ç”Ÿæˆäººç±»å¯è¯»æŠ¥å‘Š  â”‚  â†’ "åŒ—äº¬è®¢å•æœ€å¤š(100å•),å…¶æ¬¡æ˜¯ä¸Šæµ·..."
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç¬¬5æ­¥:ç”Ÿæˆå›¾è¡¨         â”‚  æ•°æ®å¯è§†åŒ–
â”‚ ç›®æ ‡:ç›´è§‚å±•ç¤ºæ•°æ®      â”‚  â†’ [æŸ±çŠ¶å›¾/é¥¼å›¾/...]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æœ¬ç« é‡ç‚¹:ç¬¬1æ­¥ - è¡¨ç»“æ„æ£€ç´¢**

---

## äºŒã€BM25 ç®—æ³•:å…³é”®è¯åŒ¹é…çš„æœ€ä½³å®è·µ

### 2.1 BM25 åŸç†

**BM25(Best Matching 25):**  åŸºäº TF-IDF æ”¹è¿›çš„æ’åºç®—æ³•

**æ ¸å¿ƒæ€æƒ³:**
1. **è¯é¢‘(TF)**: è¯åœ¨æ–‡æ¡£ä¸­å‡ºç°çš„æ¬¡æ•°è¶Šå¤š,è¶Šç›¸å…³
2. **é€†æ–‡æ¡£é¢‘ç‡(IDF)**: è¯åœ¨æ‰€æœ‰æ–‡æ¡£ä¸­è¶Šç½•è§,è¶Šé‡è¦
3. **æ–‡æ¡£é•¿åº¦å½’ä¸€åŒ–**: é¿å…é•¿æ–‡æ¡£å ä¼˜åŠ¿

**å…¬å¼(ç®€åŒ–ç‰ˆ):**
```
BM25(q, d) = Î£ IDF(qi) Ã— TF(qi, d) Ã— (k1 + 1)
                         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                         TF(qi, d) + k1 Ã— (1 - b + b Ã— |d| / avgdl)

å…¶ä¸­:
- q: æŸ¥è¯¢è¯åˆ—è¡¨
- d: æ–‡æ¡£
- TF(qi, d): qi åœ¨æ–‡æ¡£ d ä¸­çš„è¯é¢‘
- IDF(qi): qi çš„é€†æ–‡æ¡£é¢‘ç‡
- |d|: æ–‡æ¡£é•¿åº¦
- avgdl: å¹³å‡æ–‡æ¡£é•¿åº¦
- k1, b: è°ƒä¼˜å‚æ•°(é€šå¸¸ k1=1.5, b=0.75)
```

**ç›´è§‚ç†è§£:**

```
æŸ¥è¯¢:"ç»Ÿè®¡è®¢å•æ•°æ®"
åˆ†è¯:["ç»Ÿè®¡", "è®¢å•", "æ•°æ®"]

æ–‡æ¡£1(t_sales_ordersè¡¨):
"è®¢å•è¡¨ åŒ…å«è®¢å•ç¼–å· è®¢å•æ—¥æœŸ è®¢å•é‡‘é¢ç­‰å­—æ®µ"
åŒ¹é…è¯:["è®¢å•"å‡ºç°3æ¬¡]
BM25 = é«˜åˆ† âœ…

æ–‡æ¡£2(t_productsè¡¨):
"äº§å“è¡¨ åŒ…å«äº§å“åç§° äº§å“ç±»åˆ« äº§å“ä»·æ ¼ç­‰å­—æ®µ"
åŒ¹é…è¯:[]
BM25 = 0åˆ† âŒ

æ–‡æ¡£3(t_order_detailsè¡¨):
"è®¢å•æ˜ç»†è¡¨ è®°å½•æ¯ä¸ªè®¢å•çš„äº§å“æ˜ç»†æ•°æ®"
åŒ¹é…è¯:["è®¢å•"å‡ºç°1æ¬¡, "æ•°æ®"å‡ºç°1æ¬¡]
BM25 = ä¸­ç­‰åˆ†æ•°
```

### 2.2 Jieba åˆ†è¯ä¼˜åŒ–

**ä¸ºä»€ä¹ˆéœ€è¦åˆ†è¯?**

```
æŸ¥è¯¢:"ç»Ÿè®¡è®¢å•æ•°æ®"

ä¸åˆ†è¯:
["ç»Ÿè®¡è®¢å•æ•°æ®"]  # æ— æ³•åŒ¹é… "è®¢å•" æˆ– "æ•°æ®"

åˆ†è¯:
["ç»Ÿè®¡", "è®¢å•", "æ•°æ®"]  # å¯ä»¥åŒ¹é…ä»»æ„ä¸€ä¸ªè¯
```

**é¡¹ç›®å®æˆ˜(`agent/text2sql/database/db_service.py:87`):**

```python
import jieba
import re

@staticmethod
def _tokenize_text(text_str: str) -> List[str]:
    """
    å¯¹ä¸­æ–‡/è‹±æ–‡æ–‡æœ¬è¿›è¡Œåˆ†è¯,è¿‡æ»¤æ ‡ç‚¹ç¬¦å·ã€‚

    Args:
        text_str (str): è¾“å…¥æ–‡æœ¬

    Returns:
        List[str]: åˆ†è¯åçš„ token åˆ—è¡¨
    """
    # 1. è¿‡æ»¤æ ‡ç‚¹ç¬¦å·å’Œç‰¹æ®Šå­—ç¬¦
    filtered_text = re.sub(r"[^\u4e00-\u9fa5a-zA-Z0-9]", " ", text_str)

    # 2. Jieba åˆ†è¯
    tokens = jieba.lcut(filtered_text, cut_all=False)

    # 3. è¿‡æ»¤ç©ºå­—ç¬¦ä¸²
    return [token.strip() for token in tokens if token.strip()]
```

**åˆ†è¯ç¤ºä¾‹:**

```python
text = "æŸ¥è¯¢t_sales_ordersè¡¨ä¸­çš„è®¢å•æ•°æ®"
tokens = _tokenize_text(text)
print(tokens)
# è¾“å‡º: ['æŸ¥è¯¢', 't_sales_orders', 'è¡¨', 'ä¸­', 'çš„', 'è®¢å•', 'æ•°æ®']
```

**ä¼˜åŒ–ç‚¹:**
1. **å»é™¤æ ‡ç‚¹**: `[^\u4e00-\u9fa5a-zA-Z0-9]` åªä¿ç•™ä¸­è‹±æ–‡å’Œæ•°å­—
2. **ç²¾ç¡®æ¨¡å¼**: `cut_all=False` é¿å…è¿‡åº¦åˆ†è¯
3. **å»é™¤ç©ºæ ¼**: ç¡®ä¿åˆ†è¯ç»“æœå¹²å‡€

### 2.3 æ„å»ºæ£€ç´¢æ–‡æ¡£

**æ–‡æ¡£å†…å®¹è®¾è®¡:**

```python
@staticmethod
def _build_document(table_name: str, table_info: dict) -> str:
    """
    æ„å»ºç”¨äºæ£€ç´¢çš„æ–‡æ¡£æ–‡æœ¬(è¡¨å + æ³¨é‡Š + å­—æ®µå + å­—æ®µæ³¨é‡Š)ã€‚

    Args:
        table_name (str): è¡¨å
        table_info (dict): åŒ…å«åˆ—ã€å¤–é”®ã€æ³¨é‡Šç­‰ä¿¡æ¯çš„å­—å…¸

    Returns:
        str: æ‹¼æ¥åçš„æ–‡æ¡£æ–‡æœ¬
    """
    parts = [table_name]

    # æ·»åŠ è¡¨æ³¨é‡Š
    if table_info.get("table_comment"):
        parts.append(table_info["table_comment"])

    # æ·»åŠ æ‰€æœ‰å­—æ®µåå’Œæ³¨é‡Š
    for col_name, col_info in table_info.get("columns", {}).items():
        parts.append(col_name)
        if col_info.get("comment"):
            parts.append(col_info["comment"])

    return " ".join(parts)
```

**ç¤ºä¾‹:**

```python
table_name = "t_sales_orders"
table_info = {
    "table_comment": "é”€å”®è®¢å•ä¸»è¡¨",
    "columns": {
        "order_id": {"type": "INT", "comment": "è®¢å•ID"},
        "customer_id": {"type": "INT", "comment": "å®¢æˆ·ID"},
        "order_date": {"type": "DATE", "comment": "è®¢å•æ—¥æœŸ"},
        "total_amount": {"type": "DECIMAL", "comment": "è®¢å•æ€»é‡‘é¢"}
    }
}

doc = _build_document(table_name, table_info)
print(doc)
# è¾“å‡º: "t_sales_orders é”€å”®è®¢å•ä¸»è¡¨ order_id è®¢å•ID customer_id å®¢æˆ·ID order_date è®¢å•æ—¥æœŸ total_amount è®¢å•æ€»é‡‘é¢"
```

**ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡:**
1. **è¡¨åæƒé‡æœ€é«˜**: ç”¨æˆ·é€šå¸¸ä¼šæåˆ°è¡¨å
2. **è¡¨æ³¨é‡Šå¢å¼ºè¯­ä¹‰**: "é”€å”®è®¢å•ä¸»è¡¨" æ¯” "t_sales_orders" æ›´æ˜“ç†è§£
3. **å­—æ®µæ³¨é‡Šè¦†ç›–ç»†èŠ‚**: "è®¢å•æ—¥æœŸ" å¯ä»¥åŒ¹é… "æœ€è¿‘è®¢å•"

### 2.4 BM25 æ£€ç´¢å®ç°

**å®Œæ•´ä»£ç (`agent/text2sql/database/db_service.py:369`):**

```python
from rank_bm25 import BM25Okapi

def _retrieve_by_bm25(self, table_info: Dict[str, Dict], user_query: str) -> List[int]:
    """
    ä½¿ç”¨ BM25 ç®—æ³•è¿›è¡Œå…³é”®è¯åŒ¹é…æ£€ç´¢ã€‚

    Args:
        table_info (Dict[str, Dict]): è¡¨ç»“æ„
        user_query (str): ç”¨æˆ·æŸ¥è¯¢

    Returns:
        List[int]: æŒ‰ç›¸å…³æ€§æ’åºçš„ç´¢å¼•åˆ—è¡¨
    """
    if not user_query or not table_info:
        return list(range(len(table_info)))

    logger.info("ğŸ”„ æ‰§è¡Œ BM25 æ£€ç´¢...")

    # 1. æ„å»ºæ–‡æ¡£åˆ—è¡¨
    self._corpus = [self._build_document(name, info) for name, info in table_info.items()]

    # 2. åˆ†è¯
    self._tokenized_corpus = [self._tokenize_text(doc) for doc in self._corpus]
    query_tokens = self._tokenize_text(user_query)

    # 3. åˆå§‹åŒ– BM25
    bm25 = BM25Okapi(self._tokenized_corpus)

    # 4. è®¡ç®—å¾—åˆ†
    doc_scores = bm25.get_scores(query_tokens)

    # 5. å¢å¼º:è‹¥æŸ¥è¯¢è¯å‡ºç°åœ¨è¡¨æ³¨é‡Šä¸­,åˆ™æå‡åˆ†æ•°
    enhanced_scores = doc_scores.copy()
    table_comments = [info.get("table_comment", "") for info in table_info.values()]

    for i, (comment, score) in enumerate(zip(table_comments, doc_scores)):
        if score <= 0:
            continue

        # è®¡ç®—æŸ¥è¯¢è¯ä¸è¡¨æ³¨é‡Šçš„é‡å åº¦
        comment_tokens = self._tokenize_text(comment)
        overlap = set(query_tokens) & set(comment_tokens)

        if overlap:
            overlap_ratio = len(overlap) / len(set(query_tokens))
            enhanced_scores[i] += score * overlap_ratio * 1.5  # æå‡50%

    # 6. æ’åº
    scored_indices = sorted(enumerate(enhanced_scores), key=lambda x: x[1], reverse=True)

    return [idx for idx, _ in scored_indices]
```

**å¢å¼ºç­–ç•¥è§£é‡Š:**

```
ç”¨æˆ·æŸ¥è¯¢:"ç»Ÿè®¡é”€å”®è®¢å•"
æŸ¥è¯¢åˆ†è¯:["ç»Ÿè®¡", "é”€å”®", "è®¢å•"]

è¡¨1: t_sales_orders (é”€å”®è®¢å•ä¸»è¡¨)
- è¡¨æ³¨é‡Šåˆ†è¯:["é”€å”®", "è®¢å•", "ä¸»è¡¨"]
- é‡å è¯:{"é”€å”®", "è®¢å•"}
- é‡å ç‡: 2/3 = 0.67
- åŸå§‹åˆ†æ•°: 10.5
- å¢å¼ºåˆ†æ•°: 10.5 + 10.5 Ã— 0.67 Ã— 1.5 = 21.0 âœ… å¤§å¹…æå‡

è¡¨2: t_products (äº§å“ä¿¡æ¯è¡¨)
- è¡¨æ³¨é‡Šåˆ†è¯:["äº§å“", "ä¿¡æ¯", "è¡¨"]
- é‡å è¯:{}
- å¢å¼ºåˆ†æ•°: 0 âŒ ä¸å˜
```

---

## ä¸‰ã€FAISS å‘é‡æ£€ç´¢:è¯­ä¹‰ç†è§£çš„åˆ©å™¨

### 3.1 ä¸ºä»€ä¹ˆéœ€è¦å‘é‡æ£€ç´¢

**BM25 çš„å±€é™æ€§:**

```
ç”¨æˆ·æŸ¥è¯¢:"æŸ¥è¯¢å®¢æˆ·è´­ä¹°è®°å½•"

BM25 åˆ†è¯:["æŸ¥è¯¢", "å®¢æˆ·", "è´­ä¹°", "è®°å½•"]

è¡¨1: t_sales_orders (é”€å”®è®¢å•ä¸»è¡¨)
- æ–‡æ¡£:"é”€å”® è®¢å• ä¸»è¡¨ order_id customer_id ..."
- åŒ¹é…è¯:["å®¢æˆ·"(customer_id)]
- BM25åˆ†æ•°:ä½ âŒ (æ²¡æœ‰"è´­ä¹°"å…³é”®è¯)

ä½†å®é™…ä¸Š:"é”€å”®è®¢å•" å’Œ "è´­ä¹°è®°å½•" æ˜¯åŒä¹‰è¯!
```

**å‘é‡æ£€ç´¢çš„ä¼˜åŠ¿:**

```
"é”€å”®è®¢å•" â†’ å‘é‡ [0.2, 0.5, 0.8, ...]
"è´­ä¹°è®°å½•" â†’ å‘é‡ [0.3, 0.4, 0.7, ...]
ä½™å¼¦ç›¸ä¼¼åº¦: 0.85 âœ… (é«˜åº¦ç›¸ä¼¼)

"é”€å”®è®¢å•" â†’ å‘é‡ [0.2, 0.5, 0.8, ...]
"äº§å“ä¿¡æ¯" â†’ å‘é‡ [0.9, 0.1, 0.2, ...]
ä½™å¼¦ç›¸ä¼¼åº¦: 0.12 âŒ (ä¸ç›¸ä¼¼)
```

### 3.2 FAISS å‘é‡ç´¢å¼•åŸç†

**FAISS(Facebook AI Similarity Search):**  Meta å¼€å‘çš„é«˜æ•ˆç›¸ä¼¼æ€§æœç´¢åº“

**æ ¸å¿ƒæµç¨‹:**

```
1. æ–‡æœ¬ â†’ Embedding API â†’ å‘é‡
   "é”€å”®è®¢å•ä¸»è¡¨" â†’ [0.2, 0.5, 0.8, ..., 0.3]  # 1024 ç»´å‘é‡

2. å‘é‡ â†’ FAISS ç´¢å¼•
   IndexFlatIP(dimension=1024)  # å†…ç§¯ç´¢å¼•(ä½™å¼¦ç›¸ä¼¼åº¦)

3. æŸ¥è¯¢å‘é‡ â†’ æœç´¢æœ€ç›¸ä¼¼çš„ K ä¸ªå‘é‡
   "æŸ¥è¯¢è®¢å•" â†’ [0.25, 0.48, 0.75, ..., 0.32]
   search(query_vec, k=10) â†’ [ç´¢å¼•0, ç´¢å¼•5, ç´¢å¼•12, ...]
```

**ç´¢å¼•ç±»å‹é€‰æ‹©:**

| ç´¢å¼•ç±»å‹ | åŸç† | é€Ÿåº¦ | ç²¾åº¦ | é€‚ç”¨åœºæ™¯ |
|---------|------|------|------|----------|
| IndexFlatIP | æš´åŠ›æœç´¢(å†…ç§¯) | æ…¢ | 100% | æ•°æ®é‡ < 10ä¸‡ |
| IndexFlatL2 | æš´åŠ›æœç´¢(æ¬§æ°è·ç¦») | æ…¢ | 100% | æ•°æ®é‡ < 10ä¸‡ |
| IndexIVFFlat | å€’æ’ç´¢å¼• | å¿« | 95% | æ•°æ®é‡ > 10ä¸‡ |
| IndexHNSW | åˆ†å±‚å›¾ | æœ€å¿« | 98% | æ•°æ®é‡ > ç™¾ä¸‡ |

**é¡¹ç›®é€‰æ‹©:** `IndexFlatIP`(å†…ç§¯ = ä½™å¼¦ç›¸ä¼¼åº¦,å› ä¸ºå‘é‡å·²å½’ä¸€åŒ–)

### 3.3 DashScope Embedding API

**è°ƒç”¨ç¤ºä¾‹(`agent/text2sql/database/db_service.py:271`):**

```python
from openai import OpenAI
import numpy as np
import faiss

# åˆå§‹åŒ–å®¢æˆ·ç«¯
MODEL_API_KEY = os.getenv("MODEL_API_KEY")
MODEL_BASE_URL = os.getenv("MODEL_BASE_URL")
EMBEDDING_MODEL_NAME = os.getenv("EMBEDDING_MODEL_NAME")  # text-embedding-v3

client = OpenAI(api_key=MODEL_API_KEY, base_url=MODEL_BASE_URL)

@staticmethod
def _create_embeddings_with_dashscope(texts: List[str]) -> np.ndarray:
    """
    ä½¿ç”¨ DashScope API ç”Ÿæˆæ–‡æœ¬åµŒå…¥å‘é‡ã€‚

    Args:
        texts (List[str]): è¾“å…¥æ–‡æœ¬åˆ—è¡¨

    Returns:
        np.ndarray: åµŒå…¥å‘é‡æ•°ç»„
    """
    logger.info("ğŸŒ è°ƒç”¨ DashScope æ–‡æœ¬åµŒå…¥ API...")
    start_time = time.time()

    embeddings = []
    for doc in texts:
        try:
            response = client.embeddings.create(
                model=EMBEDDING_MODEL_NAME,
                input=doc
            )
            embeddings.append(response.data[0].embedding)
        except Exception as e:
            logger.error(f"âŒ åµŒå…¥ç”Ÿæˆå¤±è´¥ ({doc[:30]}...): {e}")
            embeddings.append(np.zeros(1024))  # å ä½ç¬¦

    # è½¬æ¢ä¸º numpy æ•°ç»„å¹¶å½’ä¸€åŒ–
    embeddings = np.array(embeddings).astype("float32")
    faiss.normalize_L2(embeddings)  # L2 å½’ä¸€åŒ–(ä½¿å†…ç§¯ = ä½™å¼¦ç›¸ä¼¼åº¦)

    logger.info(f"âœ… åµŒå…¥ç”Ÿæˆå®Œæˆ,è€—æ—¶ {time.time() - start_time:.2f}s")
    return embeddings
```

**å½’ä¸€åŒ–çš„é‡è¦æ€§:**

```
å‘é‡A = [3, 4]
å‘é‡B = [6, 8]

æœªå½’ä¸€åŒ–:
- å†…ç§¯ = 3Ã—6 + 4Ã—8 = 50
- ä½™å¼¦ç›¸ä¼¼åº¦ = 50 / (âˆš(9+16) Ã— âˆš(36+64)) = 50 / 50 = 1.0

å½’ä¸€åŒ–å:
- A' = [0.6, 0.8]  (é™¤ä»¥æ¨¡é•¿5)
- B' = [0.6, 0.8]  (é™¤ä»¥æ¨¡é•¿10)
- å†…ç§¯ = 0.6Ã—0.6 + 0.8Ã—0.8 = 1.0  (ç­‰äºä½™å¼¦ç›¸ä¼¼åº¦)
```

### 3.4 å‘é‡ç´¢å¼•æŒä¹…åŒ–

**ä¸ºä»€ä¹ˆéœ€è¦æŒä¹…åŒ–:**

```
é—®é¢˜:æ¯æ¬¡å¯åŠ¨æœåŠ¡éƒ½é‡æ–°è°ƒç”¨ Embedding API
- 100 å¼ è¡¨ Ã— 0.1 ç§’/è¡¨ = 10 ç§’å¯åŠ¨æ—¶é—´
- 100 å¼ è¡¨ Ã— Â¥0.0007/æ¬¡ = Â¥0.07/æ¬¡å¯åŠ¨

è§£å†³æ–¹æ¡ˆ:é¦–æ¬¡æ„å»ºåä¿å­˜åˆ°ç£ç›˜
- å¯åŠ¨æ—¶é—´: 0.5 ç§’(åŠ è½½ç´¢å¼•)
- æˆæœ¬: Â¥0(æ— APIè°ƒç”¨)
```

**æŒä¹…åŒ–å®ç°(`agent/text2sql/database/db_service.py:213`):**

```python
VECTOR_INDEX_DIR = "./vector_index"
INDEX_FILE = os.path.join(VECTOR_INDEX_DIR, "schema.index")
METADATA_FILE = os.path.join(VECTOR_INDEX_DIR, "metadata.json")

def _save_vector_index(self, table_info: Dict[str, Dict]):
    """
    å°† FAISS ç´¢å¼•å’Œå…ƒæ•°æ®ä¿å­˜åˆ°ç£ç›˜ã€‚
    """
    if self._faiss_index is None:
        return

    # ä¿å­˜ FAISS ç´¢å¼•
    faiss.write_index(self._faiss_index, INDEX_FILE)

    # ä¿å­˜å…ƒæ•°æ®
    metadata = {
        "table_names": self._table_names,
        "corpus": self._corpus,
        "fingerprint": self._generate_schema_fingerprint(table_info),
        "updated_at": pd.Timestamp.now().isoformat(),
    }
    with open(METADATA_FILE, "w", encoding="utf-8") as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)

    logger.info(f"âœ… å‘é‡ç´¢å¼•å·²ä¿å­˜è‡³: {INDEX_FILE}")
```

**Schema æŒ‡çº¹(æ£€æµ‹å˜æ›´):**

```python
@staticmethod
def _generate_schema_fingerprint(table_info: Dict[str, Dict]) -> str:
    """
    ç”Ÿæˆ schema çš„æŒ‡çº¹(MD5 å“ˆå¸Œ),ç”¨äºæ£€æµ‹å˜æ›´ã€‚
    """
    fingerprint_data = {}
    for table_name, info in table_info.items():
        fingerprint_data[table_name] = {
            "comment": info.get("table_comment", ""),
            "columns": sorted([
                f"{col_name}:{col_info.get('comment', '')}"
                for col_name, col_info in info["columns"].items()
            ])
        }
    json_str = json.dumps(fingerprint_data, sort_keys=True, ensure_ascii=False)
    return hashlib.md5(json_str.encode("utf-8")).hexdigest()
```

**åŠ è½½é€»è¾‘:**

```python
def _load_vector_index(self, table_info: Dict[str, Dict]) -> bool:
    """
    ä»ç£ç›˜åŠ è½½ FAISS å‘é‡ç´¢å¼•å’Œå…ƒæ•°æ®ã€‚

    Returns:
        bool: æ˜¯å¦åŠ è½½æˆåŠŸ
    """
    if not (os.path.exists(INDEX_FILE) and os.path.exists(METADATA_FILE)):
        logger.info("âŒ å‘é‡ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨,å°†é‡å»º")
        return False

    try:
        with open(METADATA_FILE, "r", encoding="utf-8") as f:
            metadata = json.load(f)

        # æ£€æŸ¥ schema æ˜¯å¦å˜æ›´
        current_fingerprint = self._generate_schema_fingerprint(table_info)
        if metadata.get("fingerprint") != current_fingerprint:
            logger.info("ğŸ”„ æ•°æ®åº“ schema å·²å˜æ›´,éœ€é‡å»ºå‘é‡ç´¢å¼•")
            return False

        # åŠ è½½ç´¢å¼•
        self._faiss_index = faiss.read_index(INDEX_FILE)
        self._table_names = metadata["table_names"]
        self._corpus = metadata["corpus"]

        logger.info(f"ğŸ‰ æˆåŠŸåŠ è½½å‘é‡ç´¢å¼•,åŒ…å« {len(self._table_names)} å¼ è¡¨")
        return True

    except Exception as e:
        logger.warning(f"âš ï¸ åŠ è½½å‘é‡ç´¢å¼•å¤±è´¥: {e},å°†é‡å»º")
        return False
```

### 3.5 å‘é‡æ£€ç´¢å®ç°

**å®Œæ•´ä»£ç (`agent/text2sql/database/db_service.py:335`):**

```python
def _retrieve_by_vector(self, query: str, top_k: int = 10) -> List[int]:
    """
    ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢æœ€ç›¸å…³çš„è¡¨ã€‚

    Args:
        query (str): ç”¨æˆ·è¾“å…¥çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢
        top_k (int): éœ€è¦è¿”å›çš„æœ€ç›¸ä¼¼è¡¨çš„æ•°é‡

    Returns:
        List[int]: ä¸ç”¨æˆ·æŸ¥è¯¢æœ€ç›¸ä¼¼çš„è¡¨åœ¨ corpus ä¸­çš„ç´¢å¼•åˆ—è¡¨
    """
    try:
        # 1. ç”ŸæˆæŸ¥è¯¢å‘é‡
        response = client.embeddings.create(
            model=EMBEDDING_MODEL_NAME,
            input=query
        )
        query_vec = np.array([response.data[0].embedding]).astype("float32")

        # 2. L2 å½’ä¸€åŒ–
        faiss.normalize_L2(query_vec)

        # 3. æœç´¢
        _, indices = self._faiss_index.search(query_vec, top_k)

        return indices[0].tolist()

    except Exception as e:
        logger.error(f"âŒ å‘é‡æ£€ç´¢å¤±è´¥: {e}")
        return []
```

**ä½¿ç”¨ç¤ºä¾‹:**

```python
user_query = "ç»Ÿè®¡å„çœé”€å”®é¢"

# ç”ŸæˆæŸ¥è¯¢å‘é‡
query_embedding = client.embeddings.create(
    model="text-embedding-v3",
    input=user_query
).data[0].embedding  # [0.23, 0.45, 0.78, ..., 0.12]

# FAISS æœç´¢
faiss_index.search(query_vec, k=10)
# è¿”å›: ([0.85, 0.73, 0.62, ...], [2, 5, 8, ...])
#        â†‘ ç›¸ä¼¼åº¦åˆ†æ•°            â†‘ è¡¨ç´¢å¼•

# ç´¢å¼•2 â†’ t_sales_orders
# ç´¢å¼•5 â†’ t_customers
# ç´¢å¼•8 â†’ t_order_details
```

---

## å››ã€RRF èåˆ:ç»“åˆ BM25 ä¸å‘é‡æ£€ç´¢çš„ä¼˜åŠ¿

### 4.1 ä¸ºä»€ä¹ˆéœ€è¦èåˆ

**BM25 ä¼˜åŠ¿:**
- ç²¾ç¡®åŒ¹é…å…³é”®è¯
- å¯¹è¡¨å/å­—æ®µåæ•æ„Ÿ

**å‘é‡æ£€ç´¢ä¼˜åŠ¿:**
- ç†è§£è¯­ä¹‰ç›¸ä¼¼æ€§
- å¤„ç†åŒä¹‰è¯

**å•ä¸€æ–¹æ³•çš„å±€é™:**

```
ç”¨æˆ·æŸ¥è¯¢:"æŸ¥è¯¢å®¢æˆ·è´­ä¹°è®°å½•"

BM25 Top 3:
1. t_customers (å®¢æˆ·ä¿¡æ¯è¡¨) âœ… åŒ¹é…"å®¢æˆ·"
2. t_user_qa_record (é—®ç­”è®°å½•è¡¨) âŒ åŒ¹é…"è®°å½•"
3. t_report_info (æŠ¥å‘Šè®°å½•è¡¨) âŒ åŒ¹é…"è®°å½•"

å‘é‡æ£€ç´¢ Top 3:
1. t_sales_orders (é”€å”®è®¢å•ä¸»è¡¨) âœ… è¯­ä¹‰ç›¸ä¼¼"è´­ä¹°"
2. t_order_details (è®¢å•æ˜ç»†è¡¨) âœ… è¯­ä¹‰ç›¸ä¼¼
3. t_customers (å®¢æˆ·ä¿¡æ¯è¡¨) âœ… ç›¸å…³è¡¨

èåˆå:
1. t_customers (ä¸¤è€…éƒ½é«˜åˆ†)
2. t_sales_orders (å‘é‡é«˜åˆ†)
3. t_order_details (å‘é‡é«˜åˆ†)
```

### 4.2 RRF(Reciprocal Rank Fusion) ç®—æ³•

**å…¬å¼:**

```
RRF(d) = Î£  1 / (k + rank_i(d))
       iâˆˆmethods

å…¶ä¸­:
- d: æ–‡æ¡£
- rank_i(d): æ–‡æ¡£ d åœ¨æ–¹æ³• i ä¸­çš„æ’å(ä»0å¼€å§‹)
- k: å¸¸æ•°(é€šå¸¸å–60)
```

**ç›´è§‚ç†è§£:**

```
æ–‡æ¡£A:
- BM25 æ’å: ç¬¬1å(rank=0) â†’ 1/(60+0) = 0.0167
- å‘é‡ æ’å: ç¬¬3å(rank=2) â†’ 1/(60+2) = 0.0161
- RRF å¾—åˆ†: 0.0167 + 0.0161 = 0.0328

æ–‡æ¡£B:
- BM25 æ’å: ç¬¬5å(rank=4) â†’ 1/(60+4) = 0.0156
- å‘é‡ æ’å: æœªå‡ºç°(rank=âˆ) â†’ 0
- RRF å¾—åˆ†: 0.0156

æ–‡æ¡£C:
- BM25 æ’å: ç¬¬2å(rank=1) â†’ 1/(60+1) = 0.0164
- å‘é‡ æ’å: ç¬¬1å(rank=0) â†’ 1/(60+0) = 0.0167
- RRF å¾—åˆ†: 0.0164 + 0.0167 = 0.0331 âœ… æœ€é«˜åˆ†
```

**é¡¹ç›®å®æˆ˜(`agent/text2sql/database/db_service.py:407`):**

```python
@staticmethod
def _rrf_fusion(bm25_indices: List[int], vector_indices: List[int], k: int = 60) -> List[int]:
    """
    ä½¿ç”¨ RRF(Reciprocal Rank Fusion)èåˆä¸¤ç§æ£€ç´¢ç»“æœã€‚

    Args:
        bm25_indices (List[int]): BM25 æ’åºç´¢å¼•
        vector_indices (List[int]): å‘é‡æ£€ç´¢æ’åºç´¢å¼•
        k (int): RRF å¸¸æ•°

    Returns:
        List[int]: èåˆåæ’åºçš„ç´¢å¼•åˆ—è¡¨
    """
    scores = {}

    # BM25 è´¡çŒ®
    for rank, idx in enumerate(bm25_indices):
        scores[idx] = scores.get(idx, 0) + 1 / (k + rank + 1)

    # å‘é‡æ£€ç´¢è´¡çŒ®
    for rank, idx in enumerate(vector_indices):
        scores[idx] = scores.get(idx, 0) + 1 / (k + rank + 1)

    # æŒ‰åˆ†æ•°é™åºæ’åˆ—
    sorted_indices = sorted(scores.items(), key=lambda x: -x[1])

    return [idx for idx, _ in sorted_indices]
```

### 4.3 äºŒæ¬¡è¿‡æ»¤:åªä¿ç•™åŒé‡éªŒè¯çš„å€™é€‰è¡¨

**ç­–ç•¥:äº¤é›† + RRF èåˆ**

```python
# æ··åˆæ£€ç´¢
bm25_top_indices = self._retrieve_by_bm25(all_table_info, user_query)
# [5, 2, 8, 12, 3, 7, ...]

vector_top_indices = self._retrieve_by_vector(user_query, top_k=20)
# [2, 8, 5, 15, 3, ...]

# è¿‡æ»¤:ä»…ä¿ç•™åŒæ—¶åœ¨ BM25 å‰ 50 å’Œå‘é‡ç»“æœä¸­çš„è¡¨
valid_bm25_set = set(bm25_top_indices[:50])
# {5, 2, 8, 12, 3, 7, ...}

candidate_indices = [idx for idx in vector_top_indices if idx in valid_bm25_set]
# [2, 8, 5, 3]  # 15 è¢«è¿‡æ»¤(ä¸åœ¨ BM25 å‰50)

if not candidate_indices:
    # é™çº§:å¦‚æœè¿‡æ»¤åä¸ºç©º,ä½¿ç”¨ BM25 å‰4ä¸ª
    candidate_indices = bm25_top_indices[:4]

# RRF èåˆ
fused_indices = self._rrf_fusion(bm25_top_indices, candidate_indices, k=60)
```

**ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡:**
1. **æé«˜ç²¾åº¦**: åŒé‡éªŒè¯é¿å…å•ä¸€æ–¹æ³•çš„åå·®
2. **é™çº§ä¿æŠ¤**: ç¡®ä¿æ€»æœ‰å€™é€‰è¡¨è¿”å›
3. **å‡å°‘å™ªéŸ³**: è¿‡æ»¤æ‰ä»…åœ¨ä¸€ç§æ–¹æ³•ä¸­é«˜åˆ†çš„è¯¯åŒ¹é…è¡¨

---

## äº”ã€DashScope Rerank:æœ€åçš„ç²¾æ’

### 5.1 ä¸ºä»€ä¹ˆéœ€è¦ Rerank

**é—®é¢˜:RRF èåˆä»ç„¶æ˜¯åŸºäºæ’å,æ²¡æœ‰è€ƒè™‘è¯­ä¹‰æ·±åº¦**

```
ç”¨æˆ·æŸ¥è¯¢:"ç»Ÿè®¡å„çœä»½çš„ç”µè¯ˆæ¡ˆä»¶æ•°é‡"

RRF èåˆå Top 3:
1. t_alarm_info (è¯ˆéª—æ•°æ®è¡¨) âœ… æ­£ç¡®
2. t_customers (å®¢æˆ·ä¿¡æ¯è¡¨) âŒ BM25é«˜åˆ†,ä½†ä¸ç›¸å…³
3. t_sales_orders (é”€å”®è®¢å•è¡¨) âŒ å‘é‡ç›¸ä¼¼,ä½†ä¸šåŠ¡æ— å…³

Rerank æ¨¡å‹(æ·±åº¦è¯­ä¹‰ç†è§£):
1. t_alarm_info (0.95) âœ… ä¸"ç”µè¯ˆæ¡ˆä»¶"é«˜åº¦ç›¸å…³
2. t_customers (0.12) âŒ ç›¸å…³æ€§ä½
3. t_sales_orders (0.08) âŒ ç›¸å…³æ€§ä½
```

### 5.2 DashScope GTE-Rerank-V2 API

**ç‰¹ç‚¹:**
- åŸºäº BERT çš„æ·±åº¦æ¨¡å‹
- è¾“å…¥:æŸ¥è¯¢ + æ–‡æ¡£åˆ—è¡¨
- è¾“å‡º:æ¯ä¸ªæ–‡æ¡£çš„ç›¸å…³æ€§åˆ†æ•°(0-1)

**è°ƒç”¨ç¤ºä¾‹(`agent/text2sql/database/db_service.py:427`):**

```python
import dashscope
from http import HTTPStatus

def _rerank_with_dashscope(self, query: str, candidate_tables: Dict[str, Dict]) -> List[Tuple[str, float]]:
    """
    ä½¿ç”¨ DashScope GTE-Rerank-V2 å¯¹å€™é€‰è¡¨è¿›è¡Œé‡æ’åºã€‚

    Args:
        query (str): ç”¨æˆ·æŸ¥è¯¢
        candidate_tables (Dict[str, Dict]): å€™é€‰è¡¨åŠå…¶ä¿¡æ¯

    Returns:
        List[Tuple[str, float]]: (è¡¨å, ç›¸å…³æ€§åˆ†æ•°) åˆ—è¡¨,æŒ‰åˆ†æ•°é™åº
    """
    if not self.USE_RERANKER:
        logger.debug("â­ï¸ Reranker å·²ç¦ç”¨,è·³è¿‡é‡æ’åº")
        return [(name, 1.0) for name in candidate_tables.keys()]

    try:
        # 1. æ„å»ºæ–‡æ¡£åˆ—è¡¨
        documents = []
        name_to_text = {}
        for table_name, info in candidate_tables.items():
            doc_text = self._build_document(table_name, info)
            documents.append(doc_text)
            name_to_text[table_name] = doc_text

        if not documents:
            return []

        # 2. è°ƒç”¨ Rerank API
        logger.info("ğŸ” è°ƒç”¨ GTE-Rerank-V2 è¿›è¡Œé‡æ’åº...")
        response = dashscope.TextReRank.call(
            api_key=MODEL_API_KEY,
            model=RERANK_MODEL_NAME,  # gte-rerank-v2
            query=query,
            documents=documents,
            top_n=len(documents),  # è¿”å›æ‰€æœ‰ç»“æœ
            return_documents=False,  # åªè¿”å›ç´¢å¼•å’Œåˆ†æ•°
        )

        # 3. è§£æç»“æœ
        if response.status_code == HTTPStatus.OK:
            results = []
            for item in response.output.results:
                # æ ¹æ®ç´¢å¼•æ‰¾åˆ°å¯¹åº”çš„è¡¨å
                table_name = next(
                    name for name, text in name_to_text.items()
                    if text == documents[item.index]
                )
                results.append((table_name, item.relevance_score))

            # æŒ‰åˆ†æ•°é™åºæ’åˆ—
            results.sort(key=lambda x: x[1], reverse=True)
            logger.info("âœ… Rerank å®Œæˆ")
            return results
        else:
            logger.warning(f"âš ï¸ Rerank API è°ƒç”¨å¤±è´¥: {response.message}")
            return [(name, 1.0) for name in candidate_tables.keys()]

    except Exception as e:
        logger.error(f"âŒ Rerank è¿‡ç¨‹å‡ºé”™: {e}")
        return [(name, 1.0) for name in candidate_tables.keys()]
```

**API è¿”å›ç¤ºä¾‹:**

```json
{
    "status_code": 200,
    "output": {
        "results": [
            {"index": 0, "relevance_score": 0.95},  // t_alarm_info
            {"index": 2, "relevance_score": 0.12},  // t_customers
            {"index": 1, "relevance_score": 0.08}   // t_sales_orders
        ]
    }
}
```

---

## å…­ã€å®Œæ•´æ£€ç´¢æµç¨‹

### 6.1 get_table_schema èŠ‚ç‚¹å®Œæ•´å®ç°

**æºç (`agent/text2sql/database/db_service.py:479`,ç²¾ç®€ç‰ˆ):**

```python
def get_table_schema(self, state: AgentState) -> AgentState:
    """
    æ ¹æ®ç”¨æˆ·æŸ¥è¯¢,é€šè¿‡æ··åˆæ£€ç´¢ç­›é€‰å‡ºæœ€ç›¸å…³çš„æ•°æ®åº“è¡¨ç»“æ„ã€‚
    """
    try:
        logger.info("ğŸ” å¼€å§‹è·å–æ•°æ®åº“è¡¨ schema ä¿¡æ¯")

        # 1. è·å–æ‰€æœ‰è¡¨ç»“æ„
        all_table_info = self._fetch_all_table_info()

        user_query = state.get("user_query", "").strip()
        if not user_query:
            state["db_info"] = all_table_info
            return state

        # 2. åˆå§‹åŒ–å‘é‡ç´¢å¼•(åŠ è½½æˆ–é‡å»º)
        self._initialize_vector_index(all_table_info)

        # 3. æ··åˆæ£€ç´¢:BM25 + å‘é‡æ£€ç´¢
        logger.info("ğŸ” å¼€å§‹æ··åˆæ£€ç´¢:BM25 + å‘é‡æ£€ç´¢")
        bm25_top_indices = self._retrieve_by_bm25(all_table_info, user_query)
        vector_top_indices = self._retrieve_by_vector(user_query, top_k=20)

        # 4. è¿‡æ»¤:ä»…ä¿ç•™åŒæ—¶åœ¨ BM25 å‰ 50 å’Œå‘é‡ç»“æœä¸­çš„è¡¨
        valid_bm25_set = set(bm25_top_indices[:50])
        candidate_indices = [idx for idx in vector_top_indices if idx in valid_bm25_set]

        if not candidate_indices:
            candidate_indices = bm25_top_indices[:4]  # é™çº§

        # 5. RRF èåˆ
        fused_indices = self._rrf_fusion(bm25_top_indices, candidate_indices, k=60)

        # 6. è¯„åˆ†ç­›é€‰(å–åˆ†æ•° >= 0.01 ä¸”æœ€å¤š10ä¸ª)
        selected_indices = []
        for idx in fused_indices:
            bm25_rank = bm25_top_indices.index(idx) + 1 if idx in bm25_top_indices else len(all_table_info) + 1
            vector_rank = vector_top_indices.index(idx) + 1 if idx in vector_top_indices else len(all_table_info) + 1
            score = 1 / (60 + bm25_rank) + 1 / (60 + vector_rank)
            if score >= 0.01 and len(selected_indices) < 10:
                selected_indices.append(idx)

        # 7. æ„å»ºå€™é€‰è¡¨å­—å…¸
        candidate_table_names = [self._table_names[i] for i in selected_indices]
        candidate_table_info = {name: all_table_info[name] for name in candidate_table_names}

        # 8. Rerank é‡æ’åº
        reranked_results = self._rerank_with_dashscope(user_query, candidate_table_info)
        final_table_names = [name for name, _ in reranked_results][:4]  # å– top 4

        # 9. æ„å»ºè¾“å‡º
        filtered_info = {name: all_table_info[name] for name in final_table_names}

        # 10. æ‰“å°ç»“æœæ‘˜è¦
        print(f"\nğŸ” ç”¨æˆ·æŸ¥è¯¢: {user_query}")
        print("ğŸ“Š æ£€ç´¢ä¸æ’åºç»“æœ:")
        for i, (table_name, score) in enumerate(reranked_results):
            print(f"  {i + 1}. {table_name:<15} | Rerank: {score:.3f}")

        state["db_info"] = filtered_info
        logger.info(f"âœ… æœ€ç»ˆç­›é€‰å‡º {len(filtered_info)} ä¸ªç›¸å…³è¡¨: {list(filtered_info.keys())}")

    except Exception as e:
        logger.error(f"âŒ è·å–æ•°æ®åº“è¡¨ä¿¡æ¯å¤±è´¥: {e}")
        state["db_info"] = {}

    return state
```

### 6.2 æ‰§è¡Œæµç¨‹å¯è§†åŒ–

```
ç”¨æˆ·æŸ¥è¯¢:"ç»Ÿè®¡å„çœç”µè¯ˆæ¡ˆä»¶æ•°"
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. è·å–æ‰€æœ‰è¡¨    â”‚  50å¼ è¡¨
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. BM25 æ£€ç´¢     â”‚  â†’ [5, 2, 8, 12, 3, ...]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. å‘é‡æ£€ç´¢      â”‚  â†’ [2, 8, 5, 15, 3, ...]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. äº¤é›†è¿‡æ»¤      â”‚  â†’ [2, 8, 5, 3]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. RRF èåˆ      â”‚  â†’ [2, 5, 8, 3]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. è¯„åˆ†ç­›é€‰      â”‚  â†’ [2, 5, 8, 3, 12, 7]  (10ä¸ª)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Rerank é‡æ’   â”‚  â†’ [(2, 0.95), (5, 0.78), (8, 0.45), (3, 0.12)]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. Top K æˆªæ–­    â”‚  â†’ [2, 5, 8, 3]  (4ä¸ª)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
      è¾“å‡ºåˆ° state["db_info"]
```

---

## ä¸ƒã€æœ¬ç« æ€»ç»“

### 7.1 æ ¸å¿ƒè¦ç‚¹å›é¡¾

1. **BM25 ç®—æ³•**: åŸºäºå…³é”®è¯åŒ¹é…,ä½¿ç”¨ Jieba åˆ†è¯å’Œè¡¨æ³¨é‡Šå¢å¼º
2. **FAISS å‘é‡ç´¢å¼•**: è¯­ä¹‰æ£€ç´¢,ä½¿ç”¨ DashScope Embedding API
3. **ç´¢å¼•æŒä¹…åŒ–**: MD5 æŒ‡çº¹æ£€æµ‹ schema å˜æ›´,é¿å…é‡å¤æ„å»º
4. **RRF èåˆ**: ç»“åˆ BM25 ä¸å‘é‡æ£€ç´¢ä¼˜åŠ¿,åŒé‡éªŒè¯
5. **Rerank é‡æ’**: DashScope GTE-Rerank-V2 æ·±åº¦è¯­ä¹‰ç†è§£

### 7.2 æ£€ç´¢å‡†ç¡®ç‡ä¼˜åŒ–æŠ€å·§

1. **è¡¨æ³¨é‡Šæƒé‡æå‡**: é‡å è¯æå‡ 1.5 å€åˆ†æ•°
2. **äº¤é›†è¿‡æ»¤**: åªä¿ç•™åŒæ—¶åœ¨ä¸¤ç§æ–¹æ³•ä¸­é«˜åˆ†çš„è¡¨
3. **é™çº§ä¿æŠ¤**: è¿‡æ»¤åä¸ºç©ºæ—¶ä½¿ç”¨ BM25 å‰4ä¸ª
4. **Top K æˆªæ–­**: æœ€ç»ˆåªå– 4 å¼ è¡¨,é¿å…ä¸Šä¸‹æ–‡è¿‡é•¿

### 7.3 æˆæœ¬ä¸æ€§èƒ½ä¼˜åŒ–

| ä¼˜åŒ–ç‚¹ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|-------|--------|--------|------|
| å‘é‡ç´¢å¼•æ„å»º | æ¯æ¬¡å¯åŠ¨è°ƒç”¨API | é¦–æ¬¡æ„å»ºåæŒä¹…åŒ– | å¯åŠ¨å¿« 10å€ |
| Rerank å€™é€‰è¡¨æ•° | 50å¼ è¡¨ | 10å¼ è¡¨ | æˆæœ¬é™ä½ 80% |
| æœ€ç»ˆè¿”å›è¡¨æ•° | 10å¼ è¡¨ | 4å¼ è¡¨ | Prompt ç¼©çŸ­ 60% |

### 7.4 ä¸‹ä¸€ç« é¢„å‘Š

ä¸‹ä¸€ç« æˆ‘ä»¬å°†å­¦ä¹  **Text2SQL Agent ç¬¬äºŒéƒ¨åˆ†:LangGraph å·¥ä½œæµä¸ SQL ç”Ÿæˆ**,åŒ…æ‹¬:
- Prompt Engineering è®¾è®¡ SQL ç”Ÿæˆæ¨¡æ¿
- LangGraph çŠ¶æ€å›¾å®Œæ•´æ„å»º
- æ¡ä»¶è·¯ç”±(Neo4j è¡¨å…³ç³»æŸ¥è¯¢)
- å›¾è¡¨ç±»å‹æ¨èä¸æ•°æ®æ¸²æŸ“

---

**å®Œæ•´æ–‡ä»¶æ¸…å•:**
- `agent/text2sql/database/db_service.py` (635 è¡Œ) - æ•°æ®åº“æœåŠ¡ä¸æ··åˆæ£€ç´¢
- `agent/text2sql/state/agent_state.py` (68 è¡Œ) - çŠ¶æ€å®šä¹‰
- `vector_index/schema.index` - FAISS ç´¢å¼•æ–‡ä»¶(è‡ªåŠ¨ç”Ÿæˆ)
- `vector_index/metadata.json` - å…ƒæ•°æ®æ–‡ä»¶(è‡ªåŠ¨ç”Ÿæˆ)
